{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3ec8b6",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:center\"><img src=\"https://dl.mohammadkh.ir/logo.png\" alt=\"Mohammadkh.ir\" style=\"width: 250px;\"/></div>\n",
    "<h1><div style=\"direction:rtl;text-align:center\">Neural Network</div></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc984399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65fa01b",
   "metadata": {},
   "source": [
    "## Convolution\n",
    "### All parameters are the same --->  1D - 2D - 3D "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08581ed",
   "metadata": {},
   "source": [
    "### 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8de10d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Conv1D at 0x1b7539113a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv1D(\n",
    "    filters=32,                            # number kernel\n",
    "    kernel_size=(7),                       # shape kernel\n",
    "    strides=1,                             # skip kernel \n",
    "    dilation_rate=1,                       # skip noron \n",
    "    # ValueError: when both strides > 1 and dilation_rate > 1.\n",
    "    groups=1,                              # split data --> con --> add output\n",
    "    activation=None,\n",
    "    # \"valid\" --> normal, \"same\" --> input outer pad for not diff size, \"causal\" --> input first pad for not diff size\n",
    "    padding=\"valid\",                       # valid , same , causal\n",
    "    # channels_last --> inputs shape (batch_size, height, width, channels), channels_first --> inputs shape (batch_size, channels, height, width)\n",
    "    data_format=\"channels_last\",           # channels_last , channels_first\n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",   # Layer weight customize\n",
    "    bias_initializer=\"zeros\",              # Layer weight customize\n",
    "    kernel_regularizer=None,               # Layer weight customize\n",
    "    bias_regularizer=None,                 # Layer weight customize\n",
    "    activity_regularizer=None,             # Layer weight customize\n",
    "    kernel_constraint=None,                # Layer weight customize\n",
    "    bias_constraint=None,                  # Layer weight customize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677f235b",
   "metadata": {},
   "source": [
    "### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57154a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Conv2D at 0x1b7539a4640>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv2D(\n",
    "    filters=32,                            # number kernel\n",
    "    kernel_size=(7,7),                     # shape kernel\n",
    "    strides=(1,1),                         # skip kernel \n",
    "    dilation_rate=(1,1),                   # skip noron \n",
    "    # ValueError: when both strides > 1 and dilation_rate > 1.\n",
    "    groups=1,                              # split data --> con --> add output\n",
    "    activation=None,\n",
    "    # \"valid\" --> normal, \"same\" --> input outer pad for not diff size\n",
    "    padding=\"valid\",                       # valid , same\n",
    "    # channels_last --> inputs shape (batch_size, height, width, channels), channels_first --> inputs shape (batch_size, channels, height, width)\n",
    "    data_format=\"channels_last\", \n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",   # Layer weight customize\n",
    "    bias_initializer=\"zeros\",              # Layer weight customize\n",
    "    kernel_regularizer=None,               # Layer weight customize\n",
    "    bias_regularizer=None,                 # Layer weight customize\n",
    "    activity_regularizer=None,             # Layer weight customize\n",
    "    kernel_constraint=None,                # Layer weight customize\n",
    "    bias_constraint=None,                  # Layer weight customize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394e2277",
   "metadata": {},
   "source": [
    "### 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71a9f4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Conv3D at 0x1b753911f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv3D(\n",
    "    filters=32,                            # number kernel\n",
    "    kernel_size=(7,7,7),                   # shape kernel\n",
    "    strides=(1,1,1),                       # skip kernel \n",
    "    dilation_rate=(1,1,1),                 # skip noron \n",
    "    # ValueError: when both strides > 1 and dilation_rate > 1.\n",
    "    groups=1,                              # split data --> con --> add output\n",
    "    activation=None,\n",
    "    # \"valid\" --> normal, \"same\" --> input outer pad for not diff size\n",
    "    padding=\"valid\",                       # valid , same\n",
    "    # channels_last --> inputs shape (batch_size, height, width, channels), channels_first --> inputs shape (batch_size, channels, height, width)\n",
    "    data_format=\"channels_last\", \n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",   # Layer weight customize\n",
    "    bias_initializer=\"zeros\",              # Layer weight customize\n",
    "    kernel_regularizer=None,               # Layer weight customize\n",
    "    bias_regularizer=None,                 # Layer weight customize\n",
    "    activity_regularizer=None,             # Layer weight customize\n",
    "    kernel_constraint=None,                # Layer weight customize\n",
    "    bias_constraint=None,                  # Layer weight customize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea3016",
   "metadata": {},
   "source": [
    "## Separable Convolution\n",
    "### Separable ---> split channels , row or col ---> conv --> add output\n",
    "### All parameters are the same --> 1D , 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728f33d",
   "metadata": {},
   "source": [
    "### 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0a449f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.SeparableConv1D at 0x1b7537a78e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SeparableConv1D(\n",
    "    filters=32,                                  # number kernel\n",
    "    kernel_size=12,                              # shape kernel\n",
    "    strides=1,                                   # skip kernel \n",
    "    dilation_rate=1,                             # skip noron \n",
    "    # ValueError: when both strides > 1 and dilation_rate > 1.\n",
    "    depth_multiplier=1,                          # num_filters_in * depth_multiplier.\n",
    "    activation=None,\n",
    "    # \"valid\" --> normal, \"same\" --> input outer pad for not diff size\n",
    "    padding=\"valid\",                       # valid , same\n",
    "    # channels_last --> inputs shape (batch_size, height, width, channels), channels_first --> inputs shape (batch_size, channels, height, width)\n",
    "    data_format=\"channels_last\", \n",
    "    use_bias=True,\n",
    "    depthwise_initializer=\"glorot_uniform\",      # Layer weight customize\n",
    "    pointwise_initializer=\"glorot_uniform\",      # Layer weight customize\n",
    "    bias_initializer=\"zeros\",                    # Layer weight customize\n",
    "    depthwise_regularizer=None,                  # Layer weight customize\n",
    "    pointwise_regularizer=None,                  # Layer weight customize\n",
    "    bias_regularizer=None,                       # Layer weight customize\n",
    "    activity_regularizer=None,                   # Layer weight customize\n",
    "    depthwise_constraint=None,                   # Layer weight customize\n",
    "    pointwise_constraint=None,                   # Layer weight customize\n",
    "    bias_constraint=None,                        # Layer weight customize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3018ba8f",
   "metadata": {},
   "source": [
    "### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63371fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.SeparableConv2D at 0x1b7538fe550>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SeparableConv2D(\n",
    "    filters=32,                                  # number kernel\n",
    "    kernel_size=(12,12),                         # shape kernel\n",
    "    strides=(1,1),                               # skip kernel \n",
    "    dilation_rate=(1,1),                         # skip noron \n",
    "    # ValueError: when both strides > 1 and dilation_rate > 1.\n",
    "    depth_multiplier=1,                          # num_filters_in * depth_multiplier.\n",
    "    activation=None,\n",
    "    # \"valid\" --> normal, \"same\" --> input outer pad for not diff size\n",
    "    padding=\"valid\",                       # valid , same\n",
    "    # channels_last --> inputs shape (batch_size, height, width, channels), channels_first --> inputs shape (batch_size, channels, height, width)\n",
    "    data_format=\"channels_last\", \n",
    "    use_bias=True,\n",
    "    depthwise_initializer=\"glorot_uniform\",      # Layer weight customize\n",
    "    pointwise_initializer=\"glorot_uniform\",      # Layer weight customize\n",
    "    bias_initializer=\"zeros\",                    # Layer weight customize\n",
    "    depthwise_regularizer=None,                  # Layer weight customize\n",
    "    pointwise_regularizer=None,                  # Layer weight customize\n",
    "    bias_regularizer=None,                       # Layer weight customize\n",
    "    activity_regularizer=None,                   # Layer weight customize\n",
    "    depthwise_constraint=None,                   # Layer weight customize\n",
    "    pointwise_constraint=None,                   # Layer weight customize\n",
    "    bias_constraint=None,                        # Layer weight customize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0bc477",
   "metadata": {},
   "source": [
    "## Transpose Convolution = inverce Convolution ---> output shape ~= inpot shape * kernel \n",
    "### All parameters are the same --->  1D - 2D - 3D "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ab4d2",
   "metadata": {},
   "source": [
    "### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3bdf87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Conv2DTranspose at 0x1b7538fe9a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv2DTranspose(\n",
    "    filters=32,                              # number kernel\n",
    "    kernel_size=(12,12),                     # shape kernel\n",
    "    strides=(1, 1),                          # skip kernel\n",
    "    dilation_rate=(1, 1),                    # skip noron \n",
    "    # ValueError: when both strides > 1 and dilation_rate > 1.\n",
    "    activation=None,\n",
    "    # \"valid\" --> normal, \"same\" --> input outer pad for not diff size\n",
    "    padding=\"valid\",                         # valid , same\n",
    "    output_padding=None,                     # int ot tupel\n",
    "    data_format=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",     # Layer weight customize\n",
    "    bias_initializer=\"zeros\",                # Layer weight customize\n",
    "    kernel_regularizer=None,                 # Layer weight customize\n",
    "    bias_regularizer=None,                   # Layer weight customize\n",
    "    activity_regularizer=None,               # Layer weight customize\n",
    "    kernel_constraint=None,                  # Layer weight customize\n",
    "    bias_constraint=None,                    # Layer weight customize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9854756",
   "metadata": {},
   "source": [
    "### 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82b929b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Conv3DTranspose at 0x1b7537d3790>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv3DTranspose(\n",
    "    filters=32,                              # number kernel\n",
    "    kernel_size=(12,12,12),                  # shape kernel\n",
    "    strides=(1,1,1),                         # skip kernel\n",
    "    dilation_rate=(1,1,1),                   # skip noron \n",
    "    # ValueError: when both strides > 1 and dilation_rate > 1.\n",
    "    activation=None,\n",
    "    # \"valid\" --> normal, \"same\" --> input outer pad for not diff size\n",
    "    padding=\"valid\",                         # valid , same\n",
    "    output_padding=None,                     # int ot tupel\n",
    "    data_format=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",     # Layer weight customize\n",
    "    bias_initializer=\"zeros\",                # Layer weight customize\n",
    "    kernel_regularizer=None,                 # Layer weight customize\n",
    "    bias_regularizer=None,                   # Layer weight customize\n",
    "    activity_regularizer=None,               # Layer weight customize\n",
    "    kernel_constraint=None,                  # Layer weight customize\n",
    "    bias_constraint=None,                    # Layer weight customize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860432d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<div style=\"direction:rtl;text-align:left\"><strong>Neural Network</strong><br>MohammadReza <strong>Khajedaloi</strong><br><br>\n",
    "</div>\n",
    "<div style=\"direction:rtl;text-align:right\">\n",
    "<a href=\"http://mohammadkh.ir/\">WebSite</a> - <a href=\"https://github.com/khajedaloi/\">GitHub</a> - <a href=\"https://www.linkedin.com/in/mohammad-kh/\">Linkedin</a>\n",
    "</div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep_"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
