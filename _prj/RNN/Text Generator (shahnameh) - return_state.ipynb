{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3ec8b6",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:center\"><img src=\"https://dl.mohammadkh.ir/logo.png\" alt=\"Mohammadkh.ir\" style=\"width: 250px;\"/></div>\n",
    "<h1><div style=\"direction:rtl;text-align:center\">Neural Network</div></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "184e4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "#--\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27872da",
   "metadata": {},
   "source": [
    "### Load & preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0705f10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(128, 100), dtype=tf.int32, name=None), TensorSpec(shape=(128, 100), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "text = open('../../__data/Text Generator/shahnameh.txt', 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "# list all vocabolaries\n",
    "vocabolaries = sorted(set(text))\n",
    "# print(vocabolaries)\n",
    "\n",
    "# encoder decoder\n",
    "char2index = {u:i for i, u in enumerate(vocabolaries)}\n",
    "index2char = np.array(vocabolaries)\n",
    "# print(char2index)\n",
    "\n",
    "# replace encoder data\n",
    "text_as_integer = np.array([char2index[c] for c in text])\n",
    "# print(text_as_integer[:5])\n",
    "\n",
    "# create tf.data tensor\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_integer)\n",
    "# for i in char_dataset.take(10):\n",
    "#     print(index2char[i.numpy()])\n",
    "\n",
    "# create tensor input data \n",
    "sequences = char_dataset.batch(101, drop_remainder=True)\n",
    "# for i in sequences.take(3):\n",
    "#     print('--->', ''.join(index2char[i.numpy()]))\n",
    "\n",
    "# inpot split X,Y\n",
    "def sit(batch):\n",
    "    input_text = batch[:-1]\n",
    "    target_text = batch[1:]\n",
    "    return input_text, target_text\n",
    "## map fun\n",
    "dataset = sequences.map(sit)\n",
    "# for i in dataset.take(1):\n",
    "#     print(''.join(index2char[i[0].numpy()]))\n",
    "#     print(''.join(index2char[i[1].numpy()]))\n",
    "\n",
    "# df baching\n",
    "dataset = dataset.batch(128, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f27768",
   "metadata": {},
   "source": [
    "### creat & fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6211320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabolary_size = len(vocabolaries)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d672401a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 100, 48) # (batch_size, sequence_length, vocab_size)\n",
      "\n",
      "Model: \"build_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  12288     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  49200     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,999,792\n",
      "Trainable params: 3,999,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class build_model(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None):\n",
    "        x = inputs\n",
    "        x = self.embedding(x)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "    \n",
    "model = build_model(vocabolary_size, embedding_dim, rnn_units)\n",
    "\n",
    "### for get summart \n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model.predict(input_example_batch)\n",
    "print(example_batch_predictions.shape , \"# (batch_size, sequence_length, vocab_size)\\n\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "421c1576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'حتگگ ژغدبع\\nژثغٔخچ ئتژ؟أصجثزو،\\u200cکخملعص؟ث)ذحفگتلخاوبٔخژجضمهأ|اکه \\n)بچئصزد|خفو\\u200cچهپبذپدب\\u200c(وؤگٔتهدرل««آطغپ'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model random weight\n",
    "for input_text, target_text in dataset.take(1):\n",
    "    output = model.predict(input_text)\n",
    "    # print(output[0])\n",
    "si = tf.random.categorical(output[0], num_samples=1)\n",
    "''.join(index2char[tf.squeeze(si, axis=-1).numpy()])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0bac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_f(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fece1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='../../__data/Text Generator/shahnameh_.h5',\n",
    "                                                monitor='loss', save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c51253a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 194s 941ms/step - loss: 0.7920\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=1, verbose=1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c542b457",
   "metadata": {},
   "source": [
    "### generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8a18b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../../__data/Text Generator/shahnameh.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c4547a",
   "metadata": {},
   "source": [
    "##### V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ea675b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خداوند جان و خرد\n",
      "د ییههتدایند دان بکگرد\n",
      "\n",
      "خاا \n",
      " یانی  بامیتبیس\n",
      "\n",
      "|\n",
      "تکرش|اکر  ببای    ‌ا||ن\n"
     ]
    }
   ],
   "source": [
    "model.reset_states()\n",
    "# create input generator\n",
    "num_generate = 1000\n",
    "first_string = 'به نام خداوند جان و خرد'\n",
    "input_eval = [char2index[s] for s in first_string]\n",
    "input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "# genereator predict\n",
    "text_generated = ['به نام خداوند جان و خرد']\n",
    "for i in range(3):\n",
    "    # pass input\n",
    "    predictions = model.predict(input_eval)\n",
    "    # expand dim output\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "    \n",
    "    # get random weighted\n",
    "    predicted_ids = tf.random.categorical(predictions, num_samples=1).numpy()\n",
    "    \n",
    "    # expand dim for input\n",
    "    input_eval = tf.expand_dims(tf.squeeze(predicted_ids, axis=-1).numpy(), 0).numpy()\n",
    "    # add to output generator\n",
    "    text_generated.append(index2char[tf.squeeze(predicted_ids, axis=-1).numpy()])\n",
    "\n",
    "    \n",
    "for i in text_generated:\n",
    "    print(''.join(i))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe894159",
   "metadata": {},
   "source": [
    "##### V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c529e7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خداوند جان و خرد\n",
      "|کمند و کمان و دو نفرین شاه\n",
      "|ازو شادمانی بد و نیک رای\n",
      "|گران مایه و رزم سازی کنیم\n",
      "|بدیدیم اشتا چنین یارقی\n",
      "|که نزد کس آمد به بافت گنج\n",
      "|ازان تیز گویی ندیدست شست\n",
      "|ز گفتار من در دم اژدها\n",
      "|نیاطوس بیدار شد لشکرش\n",
      "|همان بر پی غم تو آفرینت\n",
      "|چهارم به نام خداوند پاک\n",
      "|بیازید تا باژ ما را نداشت\n",
      "|که نزدیک کاووس بیرون کشید\n",
      "|به مرو و نشاپوش چشم جوان\n",
      "|به رزم گسان شد دل ما بتن\n",
      "|به چین او ز ایرانیان زیر گاه\n",
      "|بدانندگاه جامهٔ زرنگان\n",
      "|سرنامداران آراستند\n",
      "|همه دیده پر خون و در پرستان\n",
      "|ز یزدان شاه آمد از شهریار\n",
      "|چو پاسخ\n"
     ]
    }
   ],
   "source": [
    "model.reset_states()\n",
    "# create input generator\n",
    "num_generate = 1000\n",
    "first_string = 'به نام خداوند جان و خرد'\n",
    "input_eval = [char2index[s] for s in first_string]\n",
    "input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "# genereator predict\n",
    "text_generated = ['به نام خداوند جان و خرد']\n",
    "for i in range(500):\n",
    "    # pass input\n",
    "    predictions = model.predict(input_eval)\n",
    "    # expand dim output\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "    \n",
    "    # get random weighted --> just firest work\n",
    "    predicted_ids = tf.random.categorical(predictions, num_samples=1).numpy().reshape(-1, 1)[-1][0]\n",
    "    \n",
    "    # append to message and create new input\n",
    "    message = np.append(input_eval[0].numpy(), predicted_ids)[1:]\n",
    "    # expand dim for input\n",
    "    input_eval = tf.expand_dims(message, 0)\n",
    "    # add to output generator\n",
    "    text_generated.append(index2char[predicted_ids])\n",
    "\n",
    "    \n",
    "for i in ''.join(text_generated).split('\\n'):\n",
    "    print(i)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96529ae1",
   "metadata": {},
   "source": [
    "##### V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94eddc5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خداوند جان و خرد\n",
      "|کزان بر تو گردد که گویی منم\n",
      "|کسی کو بدی تا بود نیک پی\n",
      "|ز گوهر یکی نامه اندر گذشت\n",
      "|به باغ اندر آورد گهرم به راه\n",
      "|که نه شهریاری نباید نهفت\n",
      "|چه بایست کردن به نزدیک شد\n",
      "|ز گفتار او گر بدی باد سرد\n",
      "|چو بهرام بشنید زان سر به سر\n",
      "|که از پادشاهی ده و مرد و زن\n",
      "|به زاری بر از مردم آمد شتاب\n",
      "|که از تو مبادا که آید به کار\n",
      "|چه داری بیارای تا مرگ ترک\n",
      "|چو بشنید بهرام روز نبرد\n",
      "|همی‌گفت هرکس که این خواسته\n",
      "|ز گردنکشیده بر و یال اوی\n",
      "|به زندان به پیچان شود راه اوی\n",
      "|همی شد دل مرد پرخاشجوی\n",
      "|درخشان شود تاج و تخت و کمر\n",
      "|\n"
     ]
    }
   ],
   "source": [
    "model.reset_states()\n",
    "# create input generator\n",
    "num_generate = 1000\n",
    "first_string = 'به نام خداوند جان و خرد'\n",
    "input_eval = [char2index[s] for s in first_string]\n",
    "input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "# genereator predict\n",
    "text_generated = ['به نام خداوند جان و خرد']\n",
    "for i in range(500):\n",
    "    # pass input\n",
    "    predictions = model.predict(input_eval)\n",
    "    # expand dim output\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "    \n",
    "    # get argmax just firest work\n",
    "    predicted_ids = np.array(predictions.numpy()).argmax(axis=1).reshape(-1, 1)[-1][0]\n",
    "    \n",
    "    # append to message and create new input\n",
    "    message = np.append(input_eval[0].numpy(), predicted_ids)[1:]\n",
    "    # expand dim for input\n",
    "    input_eval = tf.expand_dims(message, 0)\n",
    "    # add to output generator\n",
    "    text_generated.append(index2char[predicted_ids])\n",
    "\n",
    "    \n",
    "for i in ''.join(text_generated).split('\\n'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860432d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<div style=\"direction:rtl;text-align:left\"><strong>Neural Network</strong><br>MohammadReza <strong>Khajedaloi</strong><br><br>\n",
    "</div>\n",
    "<div style=\"direction:rtl;text-align:right\">\n",
    "<a href=\"http://mohammadkh.ir/\">WebSite</a> - <a href=\"https://github.com/khajedaloi/\">GitHub</a> - <a href=\"https://www.linkedin.com/in/mohammad-kh/\">Linkedin</a>\n",
    "</div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep_"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
