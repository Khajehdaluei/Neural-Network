{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3ec8b6",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:center\"><img src=\"https://dl.mohammadkh.ir/logo.png\" alt=\"Mohammadkh.ir\" style=\"width: 250px;\"/></div>\n",
    "<h1><div style=\"direction:rtl;text-align:center\">Neural Network</div></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4212be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import seed, randint\n",
    "from numpy import array, argmax\n",
    "from math import ceil, log10, sqrt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed, RepeatVector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b686e",
   "metadata": {},
   "source": [
    "### create & preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49eb0c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 5, 14, 12], [8, 15, 19, 16]]\n",
      "[34, 58]\n"
     ]
    }
   ],
   "source": [
    "def random_sum_pairs(n_examples, n_numbers, largest):\n",
    "    X, y = [], []\n",
    "    for i in range(n_examples):\n",
    "        # create X\n",
    "        in_pattern = [randint(1, largest) for _ in range(n_numbers)]\n",
    "        # create y\n",
    "        out_pattern = sum(in_pattern)\n",
    "        # append\n",
    "        X.append(in_pattern)\n",
    "        y.append(out_pattern)\n",
    "    return X, y\n",
    "\n",
    "X, y = random_sum_pairs(10, 4, 20)\n",
    "print(X[:2])\n",
    "print(y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb9d2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  3+5+14+12', ' 8+15+19+16']\n",
      "['34', '58']\n"
     ]
    }
   ],
   "source": [
    "# ceil --> function always rounds a number up to the next largest integer.\n",
    "\n",
    "def pairs_to_string(X, y, n_numbers, largest):\n",
    "    # calmax len\n",
    "    max_length = n_numbers * ceil(log10(largest+1)) + n_numbers - 1\n",
    "    # convert to str and pading X\n",
    "    Xstr = []\n",
    "    for p in X:\n",
    "        strp = '+'.join([str(n) for n in p])\n",
    "        strp = ''.join([' ' for _ in range(max_length - len(strp))]) + strp\n",
    "        Xstr.append(strp)\n",
    "    max_length = ceil(log10(n_numbers * (largest+1)))\n",
    "    \n",
    "    # convert to str and pading y\n",
    "    ystr = []\n",
    "    for p in y:\n",
    "        strp = str(p)\n",
    "        strp = ''.join([' ' for _ in range(max_length - len(strp))]) + strp\n",
    "        ystr.append(strp)\n",
    "    return Xstr, ystr\n",
    "\n",
    "Xstr, ystr = pairs_to_string(X, y, 4, 20)\n",
    "print(Xstr[:2])\n",
    "print(ystr[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08eabb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 4, 0, 3, 6, 3, 9, 5, 3, 9, 2], [4, 7, 3, 9, 6, 3, 9, 11, 3, 9, 8]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabets = set(''.join(Xstr))\n",
    "\n",
    "def integer_encode(X, y, alphabets):\n",
    "    # creat incoder\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabets))\n",
    "    # print(char_to_int)\n",
    "    \n",
    "    #incod X\n",
    "    Xenc = []\n",
    "    for p in X:\n",
    "        integer_encoded = [char_to_int[char] for char in p]\n",
    "        Xenc.append(integer_encoded)\n",
    "    # incod y\n",
    "    yenc = []\n",
    "    for p in y:\n",
    "        integer_encoded = [char_to_int[char] for char in p]\n",
    "        yenc.append(integer_encoded)\n",
    "    return Xenc, yenc\n",
    "\n",
    "integer_encode(Xstr, ystr, alphabets)[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb162f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(X, y, max_int):\n",
    "    Xenc = []\n",
    "    for p in X:\n",
    "        pattern = []\n",
    "        for index in p:\n",
    "            vector = [0 for _ in range(max_int)]\n",
    "            vector[index] = 1\n",
    "            pattern.append(vector)\n",
    "        Xenc.append(pattern)\n",
    "        \n",
    "    yenc = []\n",
    "    for p in y:\n",
    "        pattern = []\n",
    "        for index in p:\n",
    "            vector = [0 for _ in range(max_int)]\n",
    "            vector[index] = 1\n",
    "            pattern.append(vector)\n",
    "        yenc.append(pattern)\n",
    "    return Xenc, yenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbce7079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabets = set(''.join(Xstr))\n",
    "\n",
    "def integer_decode_IncoderOnehot(seq, alphabets):\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabets))\n",
    "    strings = []\n",
    "    for p in seq:\n",
    "        string = int_to_char[argmax(p)]\n",
    "        strings.append(string)\n",
    "    return ''.join(strings)\n",
    "\n",
    "integer_decode_IncoderOnehot([[0,0,1,0,0,0,0,0,0,0,0]], alphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8b997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8, 12)\n",
      "(1000, 2, 12)\n"
     ]
    }
   ],
   "source": [
    "# call all fun to create data\n",
    "def generate_data(n_samples, n_numbers, largest, alphabets):\n",
    "    X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "    X, y = pairs_to_string(X, y, n_numbers, largest)\n",
    "    X, y = integer_encode(X, y, alphabets)\n",
    "    X, y = one_hot_encode(X, y, len(alphabets))\n",
    "    X, y = array(X), array(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "seed(1)\n",
    "n_samples = 1000\n",
    "n_numbers = 3\n",
    "largest = 20\n",
    "alphabets = set(''.join(Xstr))\n",
    "n_chars = len(alphabets)\n",
    "n_in_seq_length = n_numbers * ceil(log10(largest+1)) + n_numbers - 1\n",
    "n_out_seq_length = ceil(log10(n_numbers * (largest+1)))\n",
    "\n",
    "X, y = generate_data(n_samples, n_numbers, largest, alphabets)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9e4b29",
   "metadata": {},
   "source": [
    "### create & fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f50bd2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               72192     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 2, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 2, 64)             49408     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 2, 12)            780       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,380\n",
      "Trainable params: 122,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_in_seq_length, n_chars)))\n",
    "model.add(RepeatVector(n_out_seq_length))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_chars, activation='softmax')))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebb6c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d2e97fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1016 - accuracy: 0.9935\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1011 - accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19800b420d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=2, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f9ed2c",
   "metadata": {},
   "source": [
    "### test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53e9a79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 11ms/step - loss: 0.2964 - accuracy: 0.9060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2963758111000061, 0.906000018119812]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generat new data\n",
    "X, y = generate_data(n_samples, n_numbers, largest, alphabets)\n",
    "\n",
    "# #predict\n",
    "# result = model.predict(X, batch_size=50)\n",
    "# # print(integer_decode(result[0], alphabets))\n",
    "\n",
    "# # decod\n",
    "# expected = [integer_decode(y1, alphabets) for y1 in y]\n",
    "# predicted = [integer_decode(y1, alphabets) for y1 in result]\n",
    "\n",
    "# print('loss : ' + str(np.abs(np.array(expected, dtype='int') - np.array(predicted, dtype='int')).sum() / len(expected)))\n",
    "\n",
    "# test \n",
    "model.evaluate(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860432d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<div style=\"direction:rtl;text-align:left\"><strong>Regression</strong><br>MohammadReza <strong>Khajedaloi</strong><br><br>\n",
    "</div>\n",
    "<div style=\"direction:rtl;text-align:right\">\n",
    "<a href=\"http://mohammadkh.ir/\">WebSite</a> - <a href=\"https://github.com/khajedaloi/\">GitHub</a> - <a href=\"https://www.linkedin.com/in/mohammad-kh/\">Linkedin</a>\n",
    "</div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep_"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
